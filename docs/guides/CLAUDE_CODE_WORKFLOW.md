# Claude Code + ChainMind Workflow

## How It Works

### Primary Flow (Normal Operation)

1. **Claude Code** â†’ Uses Claude API directly (via Claude Code's built-in integration)
   - This is your primary provider
   - Best quality, best reasoning
   - Uses your Claude Pro plan ($100/month)

### Fallback Flow (When Claude Hits Token Limits)

2. **Claude Code detects token limit** â†’ Calls `chainmind_generate` tool via `engram-mcp`
3. **ChainMind** â†’ Skips Claude (already tried), goes straight to:
   - **OpenAI** (primary fallback) - Your $20 pay-as-you-go account
   - **Local models** (last resort) - Only if OpenAI unavailable

## Configuration

### Current Setup

- **Primary**: Claude (via Claude Code) âœ…
- **Fallback**: OpenAI (via ChainMind) âœ…
- **Last Resort**: Local models (Ollama) âœ…

### Why This Is Optimal

1. **Claude Code handles Claude API** - No need to duplicate
2. **OpenAI as fallback** - Good quality, cost-effective
3. **Local models last resort** - Only when APIs unavailable

## Usage

### Normal Operation

Just use Claude Code normally. It will use Claude API automatically.

### When Token Limits Hit

Claude Code will automatically call `chainmind_generate` which:
- Skips Claude (already tried)
- Uses OpenAI as fallback
- Falls back to local models if OpenAI unavailable

### Manual Override

If you want to explicitly use a different provider:

```python
# In Claude Code, call:
chainmind_generate(
    prompt="Your prompt",
    prefer_claude=False,  # Skip Claude (default)
    auto_select_model=True  # Let ChainMind choose best fallback
)
```

## Benefits

âœ… **No duplicate Claude calls** - Claude Code handles Claude, ChainMind handles fallback
âœ… **Cost efficient** - Only use OpenAI when Claude unavailable
âœ… **Seamless fallback** - Automatic when token limits hit
âœ… **Quality maintained** - OpenAI is good quality fallback

## Summary

**Flow**: Claude Code â†’ Claude API (primary) â†’ OpenAI (fallback) â†’ Local (last resort)

This is the optimal setup! ðŸŽ¯
